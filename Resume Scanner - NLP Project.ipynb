{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce042a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in c:\\users\\spattanayak\\anaconda3\\lib\\site-packages (0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt\n",
    "import docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac5af218",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = docx2txt.process('C:\\\\Users\\\\spattanayak\\\\Documents\\\\NLP\\\\Job Description.docx')\n",
    "resume = docx2txt.process('C:\\\\Users\\\\spattanayak\\\\Documents\\\\NLP\\\\Resume 1.docx')\n",
    "# resume = docx2txt.process('C:\\\\Users\\\\spattanayak\\\\Documents\\\\NLP\\\\Resume 2.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64de31b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study and transform data science prototypes\n",
      "\n",
      "Design machine learning systems\n",
      "\n",
      "Research and implement appropriate ML algorithms and tools\n",
      "\n",
      "Develop machine learning applications according to requirements\n",
      "\n",
      "Select appropriate datasets and data representation methods\n",
      "\n",
      "Run machine learning tests and experiments\n",
      "\n",
      "Perform statistical analysis and fine-tuning using test results\n",
      "\n",
      "Train and retrain systems when necessary\n",
      "\n",
      "Extend existing ML libraries and frameworks\n",
      "\n",
      "Keep abreast of developments in the field\n",
      "\n",
      "Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress\n",
      "\n",
      "Managing available resources such as hardware, data, and personnel so that deadlines are met\n",
      "\n",
      "Analyzing the ML algorithms that could be used to solve a given problem and ranking them by their success probability\n",
      "\n",
      "Exploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world\n",
      "\n",
      "Verifying data quality, and/or ensuring it via data cleaning\n",
      "\n",
      "Supervising the data acquisition process if more data is needed\n",
      "\n",
      "Finding available datasets online that could be used for training\n",
      "\n",
      "Defining validation strategies\n",
      "\n",
      "Defining the preprocessing or feature engineering to be done on a given dataset\n",
      "\n",
      "Defining data augmentation pipelines\n",
      "\n",
      "Training models and tuning their hyperparameters\n",
      "\n",
      "Analyzing the errors of the model and designing strategies to overcome them\n",
      "\n",
      "Deploying models to production\n",
      "\n",
      "{{Add any other relevant responsibilities here}}\n",
      "\n",
      "Skills\n",
      "\n",
      "Proficiency with a deep learning framework such as TensorFlow or Keras\n",
      "\n",
      "Proficiency with Python and basic libraries for machine learning such as scikit-learn and pandas\n",
      "\n",
      "Expertise in visualizing and manipulating big datasets\n",
      "\n",
      "Proficiency with OpenCV\n",
      "\n",
      "Familiarity with Linux\n",
      "\n",
      "Ability to select hardware to run an ML model with the required latency\n"
     ]
    }
   ],
   "source": [
    "print(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2942644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a List\n",
    "content = [job_description, resume]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6749be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer - Converts Text to Vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create Object of the CountVectrizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# Fit the list into the CountVectorizer\n",
    "matrix = cv.fit_transform(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fff3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to see the Similarity\n",
    "# To do so, we need to import cosine_similarity\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix = cosine_similarity(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88b59a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.73822565]\n",
      " [0.73822565 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1b9c3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume matches by:73.82256477794175%\n"
     ]
    }
   ],
   "source": [
    "print(\"Resume matches by:\"+str(similarity_matrix[1][0]*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d74fd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
